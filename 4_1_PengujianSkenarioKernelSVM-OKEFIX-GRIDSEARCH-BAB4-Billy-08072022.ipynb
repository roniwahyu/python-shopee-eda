{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "# Model Evaluation metrics \n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11072022\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now() # current date and time\n",
    "d = now.strftime(\"%d%m%Y\")\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlbb=pd.read_csv( \"hasil/2_mlbb_clean_sentiment07072022.csv\",encoding='utf-8')\n",
    "# ffm=pd.read_csv( \"hasil/2_ffm_clean_sentiment07072022.csv\",encoding='utf-8')\n",
    "# hdi=pd.read_csv( \"hasil/2_hdi_clean_sentiment07072022.csv\",encoding='utf-8')\n",
    "all=pd.read_csv( \"hasil/all_game_cleancontent_08072022_noneutral.csv\",encoding='utf-8')\n",
    "# mlbb = mlbb[['clean_content','score','label','sentiment']]\n",
    "# ffm = ffm[['clean_content','score','label','sentiment']]\n",
    "# hdi = hdi[['clean_content','score','label','sentiment']]\n",
    "\n",
    "#get sampling data random\n",
    "all= all.sample(n=2000,replace=True,random_state=42)\n",
    "#get sampling random 50% of data random \n",
    "# df = df.sample(n=3,replace=True,frac=0.5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 6)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA TRAINING & TESTING SEPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n"
     ]
    }
   ],
   "source": [
    "dataset=all\n",
    "folder=\"all_rbf_c_gamma\"\n",
    "dtlatih=70\n",
    "dtuji=100-dtlatih\n",
    "# print(dtlatih,dtuji)\n",
    "X = dataset['clean_content']     # Define feature matriX\n",
    "y = dataset['sentiment']         # Define target feature matriX\n",
    "jmluji=float(dtuji/100)\n",
    "print(jmluji)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=jmluji, random_state=42, stratify=y)\n",
    "\n",
    "datalatih=('Dataset {} {}:{} \\n [INFO] Sebaran kelas pada training  set: \\n negative: \\t {} \\n neutral: \\t{} \\n positive:\\t{} \\n'.format(dataset,int((1-jmluji)*100),int(jmluji*100),sum(y_train==0), sum(y_train==1), sum(y_train==2)))\n",
    "datauji=('[INFO] Sebaran kelas pada testing set:\\n negative: \\t{}\\n neutral: \\t{}\\n positive:\\t{} \\n'.format(sum(y_test==0), sum(y_test==1), sum(y_test==2)))\n",
    "\n",
    "dimensi_data=('[INFO] Shape Data: \\n X_train: \\t {} \\n X_test: \\t {} \\n y_train: \\t {} \\n y_test: \\t {} \\n'.format(X_train.shape, X_test.shape, y_train.shape, y_test.shape))\n",
    "\n",
    "with open('hasil/'+folder+'/4_1_LatihdanUji_gridsearch_'+str(dtlatih)+'-'+str(dtuji)+'_'+d+'.txt', 'a', encoding='utf-8') as f:\n",
    "    f.writelines(''.join(datalatih))\n",
    "    f.writelines(''.join(datauji))\n",
    "    f.writelines(''.join(dimensi_data))\n",
    "\n",
    "# print(datalatih, datauji, dimensi_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv( \"hasil/\"+folder+\"/4_1_\"+folder+\"_train_data_\"+str(dtlatih)+\"_\"+d+\".csv\", index=False, encoding='utf-8-sig')\n",
    "X_test.to_csv( \"hasil/\"+folder+\"/4_1_\"+folder+\"_test_data_\"+str(dtuji)+\"_\"+d+\".csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE EXTRACTION TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram_range = (1,2) #bigram\n",
    "ngram = (1,3) #trigram\n",
    "fs=\"trigram\"\n",
    "\n",
    "mindf = 5\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=ngram, min_df=mindf)\n",
    "vectors = tfidf.fit_transform(dataset.clean_content).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_to_df = tfidf.fit_transform(X_train).toarray()\n",
    "train_words_df = pd.DataFrame(X_train_to_df, columns=tfidf.get_feature_names())\n",
    "train_words_df.head(10)\n",
    "train_words_df.to_csv( \"hasil/\"+folder+\"/4_1_tfidf_training_data_\"+str(dtlatih)+'-'+str(dtuji)+\"_\"+fs+\"_\"+d+\".csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_to_df = tfidf.transform(X_test).toarray()\n",
    "test_words_df = pd.DataFrame(X_test_to_df, columns=tfidf.get_feature_names())\n",
    "test_words_df.head(10)\n",
    "test_words_df.to_csv( \"hasil/\"+folder+\"/4_1_tfidf_testing_data_\"+str(dtlatih)+'-'+str(dtuji)+\"_\"+fs+\"_\"+d+\".csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPELINE & GRIDSEARCH TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from pprint import pprint\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipe = Pipeline([\n",
    "    ('bag_of_words', TfidfVectorizer(ngram_range=ngram, min_df=mindf)),\n",
    "    ('estimator', SVC(random_state=42))])\n",
    "\n",
    "#create GridSearchCV object with set of possible parameters\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "gammas = [0.001, 0.01, 0.1, 1, 10,100]\n",
    "kernel = ['linear','rbf','poly','sigmoid']\n",
    "# kernel = ['rbf']\n",
    "param_grid={\n",
    "    'estimator__C': Cs,\n",
    "    'estimator__gamma': gammas,\n",
    "    'estimator__kernel': kernel\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Wall time: 30.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# scoring = {'AUCe': 'roc_auc', 'Accuracy': 'accuracy', 'prec':  'precision', 'rec': 'recall', 'f1s': 'f1','spec':make_scorer(recall_score,pos_label=0)}\n",
    "# scoring=['accuracy','recall_macro','precision_macro','f1_macro']\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid,refit = True, verbose = 3,scoring='accuracy',n_jobs=-1)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "y_pred = grid.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['bag_of_words', 'estimator']\n",
      "param_grid:\n",
      "{'estimator__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
      " 'estimator__gamma': [0.001, 0.01, 0.1, 1, 10, 100],\n",
      " 'estimator__kernel': ['rbf']}\n",
      "done in 0.000s\n",
      "\n",
      "Best score: 0.794\n",
      "Best parameters set:\n",
      "\testimator__C: '1'\n",
      "\testimator__gamma: '1'\n",
      "\testimator__kernel: 'rbf'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(classification_report(, y_test )) #print classification report\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipe.steps])\n",
    "print(\"param_grid:\")\n",
    "pprint(param_grid)\n",
    "t0 = time()\n",
    "\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "timelapse=(\"Time : done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid.best_score_)\n",
    "bestscore=(\"Best score: %0.3f\" % grid.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid.best_estimator_.get_params()\n",
    "# print(best_parameters)\n",
    "bestparam=[]\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (str(param_name), str(best_parameters[param_name])))\n",
    "    bestparam=bestparam+[{'Parameter':str(param_name),'value':str(best_parameters[param_name]),'training':str(dtlatih)}]\n",
    "    # bestjoin=bestjoin+\"\\n\"+(\"\\t%s: %r\" % (param_name, best_parameters[param_name])).join(bestjoin)\n",
    "    # bestparam=\"\".join(bestparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator__C</th>\n",
       "      <th>estimator__gamma</th>\n",
       "      <th>estimator__kernel</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.347623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.347623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.347623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.347623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.010</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.347623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   estimator__C  estimator__gamma estimator__kernel        f1\n",
       "0         0.001             0.001            linear  0.347623\n",
       "1         0.001             0.001               rbf  0.347623\n",
       "2         0.001             0.001              poly  0.347623\n",
       "3         0.001             0.001           sigmoid  0.347623\n",
       "4         0.001             0.010            linear  0.347623"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultgs=pd.concat([pd.DataFrame(grid.cv_results_[\"params\"]),pd.DataFrame(grid.cv_results_[\"mean_test_score\"], columns=[\"accuracy\"])],axis=1)\n",
    "resultgs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>value</th>\n",
       "      <th>training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>estimator__C</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>estimator__gamma</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>estimator__kernel</td>\n",
       "      <td>rbf</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Parameter value training\n",
       "0       estimator__C     1       70\n",
       "1   estimator__gamma     1       70\n",
       "2  estimator__kernel   rbf       70"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestpara=pd.DataFrame(bestparam)\n",
    "bestpara.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resultgs.to_csv( \"hasil/\"+folder+\"/4_1_resultgs_all_classifier_accuracy_\"+str(dtlatih)+'-'+str(dtuji)+\"_\"+fs+\"_\"+d+\".csv\", index=False, encoding='utf-8-sig')\n",
    "bestpara.to_csv( \"hasil/\"+folder+\"/4_1_bestparameter_\"+str(dtlatih)+'-'+str(dtuji)+\"_\"+fs+\"_\"+d+\".csv\", index=False, encoding='utf-8-sig')\n",
    "with open('hasil/'+folder+'/4_1_gridsearch_'+folder+'_'+str(dtlatih)+'-'+str(dtuji)+'_'+fs+'_'+d+'.txt', 'a', encoding='utf-8') as f:\n",
    "    f.writelines('\\n')\n",
    "    f.writelines((timelapse)+'\\n')\n",
    "    f.writelines((bestscore)+'\\n')\n",
    "    f.writelines('Best Parameter set:'+'\\n'+(str(bestparam)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predictions = grid.predict(X_test)\n",
    " \n",
    "# print classification report\n",
    "# print(classification_report(y_test, grid_predictions,output_dict=True))\n",
    "report=pd.DataFrame(classification_report(y_test, grid_predictions,output_dict=True)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score     support\n",
      "0              0.833828  0.878125  0.855403  320.000000\n",
      "2              0.851711  0.800000  0.825046  280.000000\n",
      "accuracy       0.841667  0.841667  0.841667    0.841667\n",
      "macro avg      0.842769  0.839063  0.840225  600.000000\n",
      "weighted avg   0.842173  0.841667  0.841237  600.000000\n"
     ]
    }
   ],
   "source": [
    "print(report)\n",
    "report.to_csv( \"hasil/\"+folder+\"/4_1_testreport_gridsearch_\"+str(dtlatih)+'-'+str(dtuji)+\"_\"+fs+\"_\"+d+\".csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.86       320\n",
      "           2       0.85      0.80      0.83       280\n",
      "\n",
      "    accuracy                           0.84       600\n",
      "   macro avg       0.84      0.84      0.84       600\n",
      "weighted avg       0.84      0.84      0.84       600\n",
      "\n",
      "\n",
      "[[281  39]\n",
      " [ 56 224]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, grid.predict(X_test)\n",
    "class_report=classification_report(y_true, y_pred)\n",
    "matrix=confusion_matrix(y_true, y_pred)\n",
    "print(class_report)\n",
    "print()\n",
    "print(matrix)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>281</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>56</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative                 281                  39\n",
       "Is positive                  56                 224"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,  \n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[281  39]\n",
      " [ 56 224]]\n"
     ]
    }
   ],
   "source": [
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'add' did not contain a loop with signature matching types (dtype('<U1'), dtype('int64')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3668/1952507483.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hasil/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/4_1_evaluasi_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtlatih\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtuji\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwritelines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m: ufunc 'add' did not contain a loop with signature matching types (dtype('<U1'), dtype('int64')) -> None"
     ]
    }
   ],
   "source": [
    "with open('hasil/'+folder+'/4_1_evaluasi_'+folder+'_'+str(dtlatih)+'-'+str(dtuji)+'_'+fs+'_'+d+'.txt', 'a', encoding='utf-8') as f:\n",
    "    f.writelines('\\n'+(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=1\n",
    "gam=1\n",
    "# Create and train a random forest classifier\n",
    "# forest = RandomForestClassifier()\n",
    "models = [\n",
    "          # ('k-NN', KNeighborsClassifier()),\n",
    "          ('SVC linear kernel', SVC(kernel='linear',C=C,max_iter=10000)),\n",
    "          ('SVC RBF kernel', SVC(kernel='rbf',gamma=gam,C=C)), \n",
    "          ('SVC Polynomial (degree 3)', SVC(kernel='poly',degree=3,C=C)),\n",
    "          ('SVC Sigmoid ', SVC(kernel='sigmoid',C=C,gamma=gam)),\n",
    "          # ('Naive Bayes', MultinomialNB()),\n",
    "          # ('Decision Tree', DecisionTreeClassifier()),\n",
    "          # ('Random Forest',RandomForestClassifier(n_estimators=50)),\n",
    "          # ('Regresi Linier',LogisticRegression()),\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training Menggunakan SVC linear kernel, akurasi pada training set: 0.8678571428571429 \n",
      "\n",
      "[INFO] Training Menggunakan SVC RBF kernel, akurasi pada training set: 0.9285714285714286 \n",
      "\n",
      "[INFO] Training Menggunakan SVC Polynomial (degree 3), akurasi pada training set: 0.9414285714285714 \n",
      "\n",
      "[INFO] Training Menggunakan SVC Sigmoid , akurasi pada training set: 0.8128571428571428 \n",
      "\n",
      "                  classifier   akurasi  C  Gamma training\n",
      "0          SVC linear kernel  0.867857  1      1       70\n",
      "1             SVC RBF kernel  0.928571  1      1       70\n",
      "2  SVC Polynomial (degree 3)  0.941429  1      1       70\n",
      "3               SVC Sigmoid   0.812857  1      1       70\n"
     ]
    }
   ],
   "source": [
    "pelatihan=[]\n",
    "for name, clf in models:\n",
    "  clf.fit(X_train_to_df, y_train)\n",
    "  train_acc = accuracy_score(y_train, clf.predict(X_train_to_df))\n",
    "  latih=('Dataset {}, data split : {}:{} \\n'.format(folder,(1-jmluji)*100,jmluji*100))\n",
    "  pelatihan=pelatihan+[{'classifier':name,'akurasi':train_acc,'C':C,'Gamma':gam,'training':str(dtlatih)}]\n",
    "  printed_dataset=('Dataset: {} \\t'.format(folder))\n",
    "  printed=('[INFO] Training Menggunakan {}, akurasi pada training set: {} \\n'.format(name, train_acc))\n",
    "  with open('hasil/'+folder+'/4_1_training_svm_'+folder+'_'+str(dtlatih)+'-'+str(dtuji)+'_'+fs+'_'+d+'.txt', 'a', encoding='utf-8') as f:\n",
    "    f.writelines('\\n'+(latih))\n",
    "    f.writelines(''.join(printed_dataset))\n",
    "    f.writelines(''.join(printed))\n",
    "  \n",
    "  print(printed)\n",
    "  # print(classification_report(clf.fit(X_train_to_df, y_train),y_train))\n",
    "\n",
    "  \n",
    "df_pelatihan=pd.DataFrame(pelatihan)\n",
    "print(df_pelatihan)\n",
    "df_pelatihan.to_csv( \"hasil/\"+folder+\"/4_1_training_svm_\"+folder+\"_\"+str(dtlatih)+'-'+str(dtuji)+\"_\"+fs+\"_\"+d+\".csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Testing Menggunakan SVC linear kernel, akurasi pada testing set: 0.7916666666666666 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80       313\n",
      "           2       0.79      0.77      0.78       287\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.79      0.79      0.79       600\n",
      "weighted avg       0.79      0.79      0.79       600\n",
      "\n",
      "[INFO] Testing Menggunakan SVC RBF kernel, akurasi pada testing set: 0.8416666666666667 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86       337\n",
      "           2       0.80      0.85      0.83       263\n",
      "\n",
      "    accuracy                           0.84       600\n",
      "   macro avg       0.84      0.84      0.84       600\n",
      "weighted avg       0.84      0.84      0.84       600\n",
      "\n",
      "[INFO] Testing Menggunakan SVC Polynomial (degree 3), akurasi pada testing set: 0.8166666666666667 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.79      0.84       358\n",
      "           2       0.74      0.85      0.79       242\n",
      "\n",
      "    accuracy                           0.82       600\n",
      "   macro avg       0.81      0.82      0.81       600\n",
      "weighted avg       0.83      0.82      0.82       600\n",
      "\n",
      "[INFO] Testing Menggunakan SVC Sigmoid , akurasi pada testing set: 0.7433333333333333 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.76       316\n",
      "           2       0.73      0.72      0.73       284\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "                  classifier   akurasi  C  Gamma testing\n",
      "0          SVC linear kernel  0.791667  1      1      30\n",
      "1             SVC RBF kernel  0.841667  1      1      30\n",
      "2  SVC Polynomial (degree 3)  0.816667  1      1      30\n",
      "3               SVC Sigmoid   0.743333  1      1      30\n"
     ]
    }
   ],
   "source": [
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pengujian=[]\n",
    "for name, clf in models:\n",
    "  clf.predict(X_test_to_df)\n",
    "  test_acc = accuracy_score(y_test, clf.predict(X_test_to_df))\n",
    "  latih=('Dataset {}, data split : {}:{} \\n'.format(folder,(1-jmluji)*100,jmluji*100))\n",
    "  pengujian=pengujian+[{'classifier':name,'akurasi':test_acc,'C':C,'Gamma':gam,'testing':str(dtuji)}]\n",
    "  printed_dataset=('Dataset: {} \\t'.format(folder))\n",
    "  printed=('[INFO] Testing Menggunakan {}, akurasi pada testing set: {} \\n'.format(name, test_acc))\n",
    "  with open('hasil/'+folder+'/4_1_testing_svm_'+folder+'_'+str(dtlatih)+'-'+str(dtuji)+'_'+fs+'_'+d+'.txt', 'a', encoding='utf-8') as f:\n",
    "    f.writelines('\\n'+(latih))\n",
    "    f.writelines(''.join(printed_dataset))\n",
    "    f.writelines(''.join(printed))\n",
    "  \n",
    "  print(printed)\n",
    "  print(classification_report(clf.predict(X_test_to_df),y_test))\n",
    "  test_matrix=(confusion_matrix(clf.predict(X_test_to_df),y_test))\n",
    "  df_test=pd.DataFrame(test_matrix,  \n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names)\n",
    "\n",
    "\n",
    "df_pengujian=pd.DataFrame(pengujian)\n",
    "print(df_pengujian)\n",
    "df_pengujian.to_csv( \"hasil/\"+folder+\"/4_1_testing_svm_\"+folder+\"_\"+str(dtlatih)+'-'+str(dtuji)+\"_\"+fs+\"_\"+d+\".csv\", index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "678bcfd6376b9a1d259d9993fe75604a4b4f3b2c5ff5a71eca36094cc19bcb7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
