{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import sys\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlbb=pd.read_csv( \"hasiluji06072022/1_mlbb_clean_content_07072022_bab4.csv\",encoding='utf-8')\n",
    "mlbb = mlbb[['content','clean_content','score','label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = word_tokenize((mlbb['content'][999]))\n",
    "test = mlbb['content'][999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'love', 'this', 'recent', 'update', ',', 'where', '1', 'GB', 'RAM', 'can', 'play', 'this', '.', 'But', 'i', 'got', 'this', 'problem', 'recently', '.', 'when', 'i', 'play', 'survival', '(', 'idk', 'about', 'other', 'modes', ',', 'but', 'i', 'got', 'this', 'problem', 'in', 'survival', 'so', 'far', ')', ',', 'after', 'landing', 'to', 'the', 'ground', ',', 'the', 'screen', 'is', 'all', 'black', ',', 'i', 'cant', 'see', 'anything', 'except', 'any', 'HP', 'and', 'MP', ',', 'either', 'from', 'enemies', ',', 'or', 'allies', ',', 'and', 'some', 'user', 'interface', '.', 'the', 'rest', '(', 'terrain', ',', 'obstacles', ',', 'etc', ')', 'are', 'all', 'black', '.', 'please', 'fix', 'this', '.', 'thank', 'you']\n"
     ]
    }
   ],
   "source": [
    "print(tokenize)\n",
    "# print(str(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization with WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love this recent update , where 1 GB RAM can play this . But i get this problem recently . when i play survival ( idk about other mode , but i get this problem in survival so far ) , after land to the ground , the screen be all black , i cant see anything except any HP and MP , either from enemy , or ally , and some user interface . the rest ( terrain , obstacle , etc ) be all black . please fix this . thank you\n"
     ]
    }
   ],
   "source": [
    "lemma = ' '.join([lemmatizer.lemmatize(w,get_wordnet_pos(w)) for w in tokenize])\n",
    "print(lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXTBLOB LEMMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install textblob\n",
    "from textblob import TextBlob, Word\n",
    "# w = Word(word)\n",
    "# w.lemmatize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love this recent update, where 1 GB RAM can play this. But i got this problem recently. when i play survival (idk about other modes, but i got this problem in survival so far), after landing to the ground, the screen is all black, i cant see anything except any HP and MP, either from enemies, or allies, and some user interface. the rest (terrain, obstacles, etc) are all black. please fix this. thank you\n"
     ]
    }
   ],
   "source": [
    "tblob=TextBlob(test)\n",
    "w=Word(test)\n",
    "print(tblob)\n",
    "# w.lemmatize()\n",
    "# \" \". join([w.lemmatize() for w in tblob.words])\n",
    "# print(\"Hasil Sentiment TextBlob:\")\n",
    "# print(tblob.sentiment)\n",
    "# print()\n",
    "# print(tblob.words)\n",
    "# print(w)\n",
    "# print([Word(word).lemmatize() for word in tblob.words])\n",
    "# print([Word(word).lemmatize(\"v\") for word in tblob.words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(sentence):\n",
    "\t\t'''\n",
    "\t\tUtility function to classify sentiment of passed tweet\n",
    "\t\tusing textblob's sentiment method\n",
    "\t\t'''\n",
    "\t\t# create TextBlob object of passed tweet text\n",
    "\t\tanalysis = TextBlob(sentence)\n",
    "\t\t# set sentiment\n",
    "\t\tif analysis.sentiment.polarity >= 0:\n",
    "\t\t\treturn 'positive'\n",
    "\t\telse:\n",
    "\t\t\treturn 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags(sentences):\n",
    "    analysis = TextBlob(sentences)\n",
    "    return analysis.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 'RB'),\n",
       " ('love', 'VBP'),\n",
       " ('this', 'DT'),\n",
       " ('recent', 'JJ'),\n",
       " ('update', 'NN'),\n",
       " ('where', 'WRB'),\n",
       " ('1', 'CD'),\n",
       " ('GB', 'NNP'),\n",
       " ('RAM', 'NNP'),\n",
       " ('can', 'MD'),\n",
       " ('play', 'VB'),\n",
       " ('this', 'DT'),\n",
       " ('But', 'CC'),\n",
       " ('i', 'NN'),\n",
       " ('got', 'VBD'),\n",
       " ('this', 'DT'),\n",
       " ('problem', 'NN'),\n",
       " ('recently', 'RB'),\n",
       " ('when', 'WRB'),\n",
       " ('i', 'JJ'),\n",
       " ('play', 'VBP'),\n",
       " ('survival', 'NN'),\n",
       " ('idk', 'JJ'),\n",
       " ('about', 'IN'),\n",
       " ('other', 'JJ'),\n",
       " ('modes', 'NNS'),\n",
       " ('but', 'CC'),\n",
       " ('i', 'RB'),\n",
       " ('got', 'VBD'),\n",
       " ('this', 'DT'),\n",
       " ('problem', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('survival', 'NN'),\n",
       " ('so', 'RB'),\n",
       " ('far', 'RB'),\n",
       " ('after', 'IN'),\n",
       " ('landing', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('ground', 'NN'),\n",
       " ('the', 'DT'),\n",
       " ('screen', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('all', 'DT'),\n",
       " ('black', 'JJ'),\n",
       " ('i', 'JJ'),\n",
       " ('cant', 'VBP'),\n",
       " ('see', 'VBP'),\n",
       " ('anything', 'NN'),\n",
       " ('except', 'IN'),\n",
       " ('any', 'DT'),\n",
       " ('HP', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('MP', 'NNP'),\n",
       " ('either', 'RB'),\n",
       " ('from', 'IN'),\n",
       " ('enemies', 'NNS'),\n",
       " ('or', 'CC'),\n",
       " ('allies', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('some', 'DT'),\n",
       " ('user', 'JJ'),\n",
       " ('interface', 'NN'),\n",
       " ('the', 'DT'),\n",
       " ('rest', 'NN'),\n",
       " ('terrain', 'NN'),\n",
       " ('obstacles', 'NNS'),\n",
       " ('etc', 'NN'),\n",
       " ('are', 'VBP'),\n",
       " ('all', 'DT'),\n",
       " ('black', 'JJ'),\n",
       " ('please', 'VB'),\n",
       " ('fix', 'NN'),\n",
       " ('this', 'DT'),\n",
       " ('thank', 'NN'),\n",
       " ('you', 'PRP')]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment(test)\n",
    "get_tags(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_with_postag(sentence):\n",
    "    sent = TextBlob(sentence)\n",
    "    tag_dict = {\"J\": 'a', \n",
    "                \"N\": 'n', \n",
    "                \"V\": 'v', \n",
    "                \"R\": 'r'}\n",
    "    words_and_tags = [(w, tag_dict.get(pos[0], 'n')) for w, pos in sent.tags]    \n",
    "    lemmatized_list = [wd.lemmatize(tag) for wd, tag in words_and_tags]\n",
    "    return \" \".join(lemmatized_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"just recently it ca n't even start a game It always crash on hero selection screen Than after restart it crash again at load screen always at around 20 % I have try restarting reload reinstall the game turn off Samsung game launcher etc Nothing work So the problem be not on the phone It have work wonderfully before for three year\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize_with_postag(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: list indices must be integers or slices, not str; perhaps you missed a comma?\n",
      "<>:6: SyntaxWarning: list indices must be integers or slices, not str; perhaps you missed a comma?\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_1736\\327700737.py:6: SyntaxWarning: list indices must be integers or slices, not str; perhaps you missed a comma?\n",
      "  print([i]['content'])\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_1736\\327700737.py:6: SyntaxWarning: list indices must be integers or slices, not str; perhaps you missed a comma?\n",
      "  print([i]['content'])\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_1736\\327700737.py:6: SyntaxWarning: list indices must be integers or slices, not str; perhaps you missed a comma?\n",
      "  print([i]['content'])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\!MYDOCUMENTS2021\\!!BILLY-2022\\!!PYTHON\\!!CONTOHPERINTIS2022\\LEXICON-TEXTBLOB-LEMMA.ipynb Cell 15'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%21MYDOCUMENTS2021/%21%21BILLY-2022/%21%21PYTHON/%21%21CONTOHPERINTIS2022/LEXICON-TEXTBLOB-LEMMA.ipynb#ch0000015?line=2'>3</a>\u001b[0m \u001b[39m# tweets.head()\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%21MYDOCUMENTS2021/%21%21BILLY-2022/%21%21PYTHON/%21%21CONTOHPERINTIS2022/LEXICON-TEXTBLOB-LEMMA.ipynb#ch0000015?line=3'>4</a>\u001b[0m \u001b[39m# columns=list(tweets)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%21MYDOCUMENTS2021/%21%21BILLY-2022/%21%21PYTHON/%21%21CONTOHPERINTIS2022/LEXICON-TEXTBLOB-LEMMA.ipynb#ch0000015?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tweets\u001b[39m.\u001b[39miterrows():\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/%21MYDOCUMENTS2021/%21%21BILLY-2022/%21%21PYTHON/%21%21CONTOHPERINTIS2022/LEXICON-TEXTBLOB-LEMMA.ipynb#ch0000015?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m([i][\u001b[39m'\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "# def test_sentiment(sentence):\n",
    "tweets=mlbb[:2]\n",
    "# tweets.head()\n",
    "# columns=list(tweets)\n",
    "for i in tweets.iterrows():\n",
    "    print([i]['content'])\n",
    "    # print(tweets['content'].values)\n",
    "    # print(get_sentiment(tweets['content'].values))\n",
    "    # ptweets = [tweet for tweet in columns if get_sentiment(tweets['content']) == 'positive']\n",
    "# for i,t in tweets.iterrows():\n",
    "    # print(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "678bcfd6376b9a1d259d9993fe75604a4b4f3b2c5ff5a71eca36094cc19bcb7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
